{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEGNET \n",
    "### Sheth Riya Nimish\n",
    "### A0176880R\n",
    "e0235287@u.nus.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source\n",
    "\n",
    "#### Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals\n",
    "\n",
    "#### Chi Chen, Weike Ye, Yunxing Zuo, Chen Zheng, and Shyue Ping Ong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen import Structure, Lattice\n",
    "from megnet.models import MEGNetModel\n",
    "from megnet.data.crystal import CrystalGraph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat_bond = 10\n",
    "r_cutoff = 5\n",
    "gaussian_centers = np.linspace(0, r_cutoff + 1, nfeat_bond)\n",
    "gaussian_width = 0.5\n",
    "graph_converter = CrystalGraph(cutoff=r_cutoff)\n",
    "model = MEGNetModel(graph_converter=graph_converter, centers=gaussian_centers, width=gaussian_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp= pd.read_csv(\"trytry.csv\")\n",
    "filenames= tp['Material'].values.tolist()\n",
    "propertylist= tp['Property'].values.tolist()\n",
    "actual= tp['Actual'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riyasheth/.local/lib/python3.8/site-packages/pymatgen/io/cif.py:1123: UserWarning: Issues encountered while parsing CIF: Some fractional co-ordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: %s\" % \"\\n\".join(self.warnings))\n"
     ]
    }
   ],
   "source": [
    "structure=[]\n",
    "for i in range (1, len(filenames)):\n",
    "    temp= \"cifcopy/\" +filenames[i]+ \".cif\"\n",
    "    structure.append(Structure.from_file(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 34s 1s/step - loss: 0.3136\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.2513\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 37s 2s/step - loss: 0.2490\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.2489\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.2483\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.2472\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.2456\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 44s 2s/step - loss: 0.2465\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 58s 3s/step - loss: 0.2449\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 57s 2s/step - loss: 0.2436\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 38s 2s/step - loss: 0.2444\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 36s 2s/step - loss: 0.2455\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 39s 2s/step - loss: 0.2447\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 126s 5s/step - loss: 0.2435\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 90s 4s/step - loss: 0.2442\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 204s 9s/step - loss: 0.2441\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 19s 834ms/step - loss: 0.2445\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 19s 839ms/step - loss: 0.2437\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 20s 855ms/step - loss: 0.2444\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 0.2439\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 20s 859ms/step - loss: 0.2432\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 21s 928ms/step - loss: 0.2452\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 23s 1s/step - loss: 0.2437\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 18s 788ms/step - loss: 0.2435\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 18s 784ms/step - loss: 0.2437\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 18s 791ms/step - loss: 0.2441\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.2426\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 19s 823ms/step - loss: 0.2427\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 19s 834ms/step - loss: 0.2444\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 20s 876ms/step - loss: 0.2449\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 21s 909ms/step - loss: 0.2447\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 21s 928ms/step - loss: 0.2430\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 21s 902ms/step - loss: 0.2439\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 20s 884ms/step - loss: 0.2431\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 19s 846ms/step - loss: 0.2427\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 19s 832ms/step - loss: 0.2424\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 19s 822ms/step - loss: 0.2434\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 19s 830ms/step - loss: 0.2440\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 19s 820ms/step - loss: 0.2445\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 19s 808ms/step - loss: 0.2435\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 19s 810ms/step - loss: 0.2428\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 19s 832ms/step - loss: 0.2431\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 19s 808ms/step - loss: 0.2433\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 19s 806ms/step - loss: 0.2425\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 18s 795ms/step - loss: 0.2429\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 18s 797ms/step - loss: 0.2432\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 19s 810ms/step - loss: 0.2419\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.2434\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.2426\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.2445\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 19s 815ms/step - loss: 0.2434\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 18s 776ms/step - loss: 0.2429\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 18s 776ms/step - loss: 0.2436\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.2428\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 19s 844ms/step - loss: 0.2433\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 22s 937ms/step - loss: 0.2442\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 20s 849ms/step - loss: 0.2435\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 18s 778ms/step - loss: 0.2437\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 18s 797ms/step - loss: 0.2427\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 18s 782ms/step - loss: 0.2433\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 18s 775ms/step - loss: 0.2430\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 18s 782ms/step - loss: 0.2424\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 18s 787ms/step - loss: 0.2423\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.2427\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 18s 785ms/step - loss: 0.2425\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 18s 777ms/step - loss: 0.2424\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 18s 784ms/step - loss: 0.2430\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 19s 827ms/step - loss: 0.2431\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 20s 878ms/step - loss: 0.2434\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 19s 840ms/step - loss: 0.2427\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 20s 853ms/step - loss: 0.2425\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 20s 870ms/step - loss: 0.2419\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 18s 777ms/step - loss: 0.2425\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 18s 767ms/step - loss: 0.2423\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 18s 787ms/step - loss: 0.2430\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 19s 830ms/step - loss: 0.2423\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 19s 837ms/step - loss: 0.2433\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 18s 783ms/step - loss: 0.2428\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 18s 794ms/step - loss: 0.2424\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 18s 780ms/step - loss: 0.2434\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 18s 779ms/step - loss: 0.2427\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 18s 791ms/step - loss: 0.2421\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 18s 799ms/step - loss: 0.2424\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 18s 781ms/step - loss: 0.2432\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 18s 778ms/step - loss: 0.2430\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 18s 798ms/step - loss: 0.2422\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 18s 790ms/step - loss: 0.2413\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 19s 831ms/step - loss: 0.2435\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 18s 794ms/step - loss: 0.2429\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 19s 813ms/step - loss: 0.2426\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 18s 788ms/step - loss: 0.2425\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 19s 817ms/step - loss: 0.2426\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 18s 799ms/step - loss: 0.2429\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 20s 856ms/step - loss: 0.2420\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 20s 890ms/step - loss: 0.2423\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 23s 994ms/step - loss: 0.2436\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 20s 852ms/step - loss: 0.2417\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 20s 864ms/step - loss: 0.2433\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 20s 867ms/step - loss: 0.2417\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 20s 863ms/step - loss: 0.2433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<megnet.models.megnet.MEGNetModel at 0x148c0c1f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(structure, propertylist, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy():\n",
    "    choice= [0, 1]\n",
    "    count=0\n",
    "    for i in range (0, len(structure)):\n",
    "        temp= model.predict_structure(structure[i])\n",
    "        t= temp[0]\n",
    "        result= random.choices(choice, weights= (1-t, t), k=1)\n",
    "        if result[0] == propertylist[i]:\n",
    "            count= count+1\n",
    "            \n",
    "    accuracy= count/len(structure)\n",
    "    print(\"The accuracy is\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.5123995808592385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5123995808592385"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 25s 1s/step - loss: 15.1429\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.5213\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 22s 953ms/step - loss: 14.4431\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 26s 1s/step - loss: 14.2461\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.3503\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.7767\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1856\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.0517\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1424\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1434\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.0617\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 13.9007\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.0338\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 27s 1s/step - loss: 13.9452\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 30s 1s/step - loss: 13.9152\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 25s 1s/step - loss: 13.9829\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 26s 1s/step - loss: 14.1215\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 23s 999ms/step - loss: 14.0223\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 27s 1s/step - loss: 14.4801\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 29s 1s/step - loss: 13.7965\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 29s 1s/step - loss: 13.7759\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 25s 1s/step - loss: 13.7079\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 28s 1s/step - loss: 13.7807\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 27s 1s/step - loss: 13.9569\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 25s 1s/step - loss: 13.7991\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.8489\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.2384\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 13.9000\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1153\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 23s 994ms/step - loss: 13.7881\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 20s 882ms/step - loss: 14.4373\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 21s 914ms/step - loss: 13.7505\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 14.1262\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 23s 986ms/step - loss: 13.9195\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.6765\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 22s 963ms/step - loss: 13.7724\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 14.3494\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.8356\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 22s 949ms/step - loss: 13.7280\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 13.7591\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 22s 976ms/step - loss: 14.1030\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.8126\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.7890\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 20s 890ms/step - loss: 14.1682\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 31s 1s/step - loss: 13.8804\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 28s 1s/step - loss: 13.8664\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 28s 1s/step - loss: 13.7070\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 26s 1s/step - loss: 13.8209\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 23s 1s/step - loss: 13.8596\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 24s 1s/step - loss: 13.6906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<megnet.models.megnet.MEGNetModel at 0x14ce50160>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(structure, actual, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building my own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure Summary\n",
       "Lattice\n",
       "    abc : 3.21119894 3.21143469 20.005301\n",
       " angles : 90.0 90.0 119.99758194\n",
       " volume : 178.6703999058667\n",
       "      A : 3.21119894 0.0 1.9662922516481867e-16\n",
       "      B : -1.6055999689589022 2.7812517879211454 1.966436606889636e-16\n",
       "      C : 0.0 0.0 20.005301\n",
       "PeriodicSite: Ga (-0.0000, 1.8542, 10.0006) [0.3333, 0.6667, 0.4999]\n",
       "PeriodicSite: N (-0.0000, 0.0002, 10.0047) [0.0000, 0.0001, 0.5001]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure Summary\n",
       "Lattice\n",
       "    abc : 2.67149725 2.66230307 22.343883\n",
       " angles : 90.0 90.0 90.0\n",
       " volume : 158.91718847411965\n",
       "      A : 2.67149725 0.0 1.6358202780717281e-16\n",
       "      B : -1.630190466517836e-16 2.66230307 1.630190466517836e-16\n",
       "      C : 0.0 0.0 22.343883\n",
       "PeriodicSite: Ga (-0.0000, 1.9967, 12.4884) [0.0000, 0.7500, 0.5589]\n",
       "PeriodicSite: Ga (-0.0000, 0.6656, 9.8554) [0.0000, 0.2500, 0.4411]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from megnet.layers import MEGNetLayer, Set2Set\n",
    "\n",
    "n_atom_feature= 20\n",
    "n_bond_feature = 10\n",
    "n_global_feature = 2\n",
    "\n",
    "# Define model inputs\n",
    "int32 = 'int32'\n",
    "x1 = Input(shape=(None, n_atom_feature)) # atom feature placeholder\n",
    "x2 = Input(shape=(None, n_bond_feature)) # bond feature placeholder\n",
    "x3 = Input(shape=(None, n_global_feature)) # global feature placeholder\n",
    "x4 = Input(shape=(None,), dtype=int32) # bond index1 placeholder\n",
    "x5 = Input(shape=(None,), dtype=int32) # bond index2 placeholder\n",
    "x6 = Input(shape=(None,), dtype=int32) # atom_ind placeholder\n",
    "x7 = Input(shape=(None,), dtype=int32) # bond_ind placeholder\n",
    "xs = [x1, x2, x3, x4, x5, x6, x7]\n",
    "\n",
    "\n",
    "# Pass the inputs to the MEGNetLayer layer\n",
    "# Here the list are the hidden units + the output unit, \n",
    "# you can have others like [n1] or [n1, n2, n3 ...] if you want. \n",
    "out = MEGNetLayer([32, 16], [32, 16], [32, 16], pool_method='mean', activation='relu')(xs)\n",
    "\n",
    "# the output is a tuple of new graphs V, E and u\n",
    "# Since u is a per-structure quantity, \n",
    "# we can directly use it to predict per-structure property\n",
    "out = Dense(1)(out[2])\n",
    "\n",
    "# Set up the model and compile it!\n",
    "model = Model(inputs=xs, outputs=out)\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'pymatgen.core.structure.Structure'>, (<class 'list'> containing values of types {\"<class 'int'>\"})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b3de7df0eff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    966\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'pymatgen.core.structure.Structure'>, (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ],
   "source": [
    "model.fit(structure[0], [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficulties:\n",
    "Further improvment\n",
    "Regression\n",
    "Error in making model\n",
    "Third paper\n",
    "Can other algoirthms like LTSM, CNN work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
